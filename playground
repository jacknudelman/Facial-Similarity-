import torch
from data_extraction import *
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import cv2
import matplotlib.pyplot as plt
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
import random
from scipy.ndimage.interpolation import shift
import sys
# from p1a import Net
# import torchsample

import numpy as np

class Net(nn.Module):

    def __init__(self, batchSize):
        super(Net, self).__init__()
        self.batchSize = batchSize
        self.maxPool = nn.MaxPool2d(2, stride=(2,2))
        self.linearLayer1 = nn.Linear(131072, 1024)
        self.linearLayer2 = nn.Linear(2048, 1)

        self.conv1 = nn.Conv2d(3, 64, 5, stride=(1,1), padding=2)
        self.batchNorm1 = nn.BatchNorm2d(64)

        self.conv2 = nn.Conv2d(64, 128, 5, stride=(1,1), padding=2)
        self.batchNorm2 = nn.BatchNorm2d(128)

        self.conv3 = nn.Conv2d(128, 256, 3, stride=(1,1), padding=1)
        self.batchNorm3 = nn.BatchNorm2d(256)

        self.conv4 = nn.Conv2d(256, 512, 3, stride=(1,1), padding=1)
        self.batchNorm4 = nn.BatchNorm2d(512)

        self.batchNorm5 = nn.BatchNorm2d(1024)

    def forward1(self, x):

        x = self.conv1(x)
        # x.size()
        x = F.relu(x)
        x = self.batchNorm1(x)
        x = self.maxPool(x)

        x = self.conv2(x)
        x = F.relu(x)
        x = self.batchNorm2(x)
        x = self.maxPool(x)

        x = self.conv3(x)
        x = F.relu(x)
        x = self.batchNorm3(x)
        x = self.maxPool(x)

        x = self.conv4(x)
        x = F.relu(x)
        x = self.batchNorm4(x)

        # flatten
        x = x.view(-1, self.num_flat_features(x))

        x = self.linearLayer1(x)

        x = F.relu(x)
        x = self.batchNorm5(x)
        return x

    def forward(self, img1, img2):
        img1 = self.forward1(img1)
        img2 = self.forward1(img2)

        z = torch.cat((img1, img2), 1)
        z = self.linearLayer2(z)
        z = F.sigmoid(z)

        return z

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


def show_batch(sample_batch):
    images_batch1 = sample_batch[0]
    images_batch2 = sample_batch[1]

    grid1 = utils.make_grid(images_batch1).numpy().transpose((1, 2, 0))
    # print grid1.shape
    plt.imshow(grid1)
    plt.axis('off')
    plt.ioff()
    plt.show()

    grid2 = utils.make_grid(images_batch2).numpy().transpose((1, 2, 0))
    plt.imshow(grid2)
    plt.axis('off')
    plt.ioff()
    plt.show()

def create_transform_list():
    possible_data_augmenters = [[transforms.RandomHorizontalFlip], [transforms.RandomHorizontalFlip],[transforms.CenterCrop(np.floor(128 * random.uniform(0.7, 1.3))), transforms.Scale((128, 128))], [lambda im: rotate(im,random.randint(-30,30), resize=True )], [lambda im: Image.fromarray(cv2.warpAffine(np.array(im), np.float32([[1, 0, random.randint(-10,10)], [0, 1, random.randint(-10,10)]])))]]
    trans = list()
    trans.append([transforms.Scale((128, 128))])
    num_additional_transformers = random.randint(1,len(possible_data_augmenters))
    indices = np.random.choice(len(possible_data_augmenters), num_additional_transformers, replace=False)
    trans.extend([possible_data_augmenters[i] for i in indices])
    trans.append([transforms.ToTensor()])
    flat = [x for sublist in trans for x in sublist]
    return flat

def read_inputs():
    #  torchsample.transforms.Rotate(30)
    # lambda im: im.putdata(shift(np.array(im), (random.randint(-10,10), random.randint(-10,10))))
    transformation = transforms.Compose([transforms.Scale((128, 128)), lambda im: Image.fromarray(cv2.warpAffine(  np.array(im), np.float32([[1, 0, random.randint(-10,10)], [0, 1, random.randint(-10,10)]]),  (np.array(im).shape[1], np.array(im).shape[0])   )), transforms.Scale((128, 128)), transforms.ToTensor()])
    transformation1 = transforms.Compose([transforms.Scale((128, 128)), transforms.CenterCrop(128 * 0.7), transforms.Scale((128, 128)), transforms.ToTensor() ])

    rand_face_dataset = RandFaceDataset(csv_file='small_sample.txt', root_dir='lfw/', transform=transformation)
    face_dataset = FaceDataset(csv_file='small_sample.txt', root_dir='lfw/', transform=transformation)
    # face_dataset1 = FaceDataset(csv_file='small_sample.txt', root_dir='lfw/', transform=transformation1)

    rand_dataloader = DataLoader(rand_face_dataset, batch_size=2, shuffle=False, num_workers=1)
    dataloader = DataLoader(face_dataset, batch_size=2, shuffle=False, num_workers=1)
    # dataloader1 = DataLoader(face_dataset1, batch_size=2, shuffle=False, num_workers=1)
    net = Net(2)

    # trans =[transforms.Scale((128, 128)), transforms.RandomHorizontalFlip(), transforms.RandomHorizontalFlip(),transforms.CenterCrop(np.floor(128 * random.uniform(0.7, 1.3))), transforms.Scale((128, 128)), lambda im: im.rotate(random.randint(-30,30), expand=1 ), transforms.Scale((128, 128)), lambda im: Image.fromarray(cv2.warpAffine(np.array(im), np.float32([[1, 0, random.randint(-10,10)], [0, 1, random.randint(-10,10)]]), (np.array(im).shape[1], np.array(im).shape[0]))), transforms.ToTensor()]
    # face_dataset.transform = transforms.Compose(trans)
    for sample_batch in rand_dataloader:
        # labels = sample_batch['label'].type(torch.DoubleTensor)
        # labels = labels.view(-1, 1)
        # print sample_batch[0].size()
        # print type(sample_batch[0])
        # out = net(Variable(sample_batch['image1'], requires_grad=False), Variable(sample_batch['image2'], requires_grad=False))
        # labels = sample_batch['label'].type(torch.FloatTensor)
        # labels = labels.view(-1, 1)
        # target = Variable(labels, requires_grad=False)
        # print out.size()
        # out = out.view(2, 1)
        # print out.size()
        # print target.size()
        # print out.data[0]
        # print out.data[0][0]
        # print target[0]
        # print target[0][0]
        # break
        # print out[:].size()
        plt.figure()
        # print 'in first'
        show_batch(sample_batch)
        print
        break
    for sample_batch in dataloader:
        # labels = sample_batch['label'].type(torch.DoubleTensor)
        # labels = labels.view(-1, 1)
        # print sample_batch[0].size()
        # print type(sample_batch[0])
        # out = net(Variable(sample_batch['image1'], requires_grad=False), Variable(sample_batch['image2'], requires_grad=False))
        # labels = sample_batch['label'].type(torch.FloatTensor)
        # labels = labels.view(-1, 1)
        # target = Variable(labels, requires_grad=False)
        # print out.size()
        # out = out.view(2, 1)
        # print out.size()
        # print target.size()
        # print out.data[0]
        # print out.data[0][0]
        # print target[0]
        # print target[0][0]
        # break
        # print out[:].size()
        plt.figure()
        # print 'in first'
        show_batch(sample_batch)
        print

        # break
    # face_dataset.transformation = transformation1
    # for sample_batch in dataloader:
    #     print 'in second'
    #     plt.figure()
    #     show_batch(sample_batch)
    #     break

def shift_image(im):
    x = np.zeros((im.size[1], im.size[0]))
    # print x.shape
    print type(shift(np.array(im), (random.randint(-10,10), random.randint(-10,10)), output=x))
    return x

def print_graphs():
    img = cv2.imread('fig.png')
    plt.title('train loss')
    plt.imshow(img)
    plt.show()
    plt.clf()

    img = cv2.imread('fig_accuracy.png')
    plt.title('test loss')
    plt.imshow(img)
    plt.show()
    plt.clf()

    img = cv2.imread('aug_fig.png')
    plt.title('test loss')
    plt.imshow(img)
    plt.show()
    plt.clf()



    img = cv2.imread('aug_fig_accuracy.png')
    plt.title('test loss')
    plt.imshow(img)
    plt.show()
    plt.clf()

    img = cv2.imread('figb.png')
    plt.title('train loss')
    plt.imshow(img)
    plt.show()
    plt.clf()

    img = cv2.imread('figb_accuracy.png')
    plt.title('test loss')
    plt.imshow(img)
    plt.show()
    plt.clf()

    # img = cv2.imread('aug_figb.png')
    # plt.title('test loss')
    # plt.imshow(img)
    # plt.show()
    # plt.clf()



    # img = cv2.imread('aug_figb_accuracy.png')
    # plt.title('test loss')
    # plt.imshow(img)
    # plt.show()
    # plt.clf()

def run_test():
    net = Net(20).cuda()
    net.load_state_dict(torch.load('weights_file'))
    # print 'created net'
    train_transformation = transforms.Compose([transforms.Scale((128, 128)), transforms.ToTensor()])
    train_face_dataset = FaceDataset(csv_file='small_sample.txt', root_dir='lfw/', transform=train_transformation)
    train_dataloader = DataLoader(train_face_dataset, batch_size=net.batchSize, shuffle=False, num_workers=net.batchSize)

    test_transformation = transforms.Compose([transforms.Scale((128, 128)), transforms.ToTensor()])
    test_face_dataset = FaceDataset(csv_file='small_test.txt', root_dir='lfw/', transform=test_transformation)
    test_dataloader = DataLoader(test_face_dataset, batch_size=net.batchSize, shuffle=False, num_workers=net.batchSize)

    learning_rate = 1e-6
    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)
    criterion = nn.BCELoss()

    num_correctly_matched = 0
    num_images = 0
    bathnum = 0
    for sample_batch in train_dataloader:
        # print bathnum
        bathnum += 1
        img1 = Variable(sample_batch[0], requires_grad=False, volatile=True).type(torch.FloatTensor)
        img2 = Variable(sample_batch[1], requires_grad=False, volatile=True).type(torch.FloatTensor)

        out = net(img1.cuda(), img2.cuda())
        labels = torch.from_numpy(np.array([float(i) for i in sample_batch[2]])).view(-1, 1)
        labels = labels.type(torch.FloatTensor)
        target = Variable(labels).cuda()

        # loss = criterion(out, target)
        print torch.stack([out, target], dim=1)
        num_images += target.size()[0]
        for i in range(target.size()[0]):
            if((target.data[i][0] == 1 and out.data[i][0] >= 0.5) or (target.data[i][0] == 0 and out.data[i][0] < 0.5)):
                num_correctly_matched += 1
    print num_images
    print num_correctly_matched
    print 'final average training accuracy = ', float(num_correctly_matched) / num_images


    num_correctly_matched = 0
    num_images = 0
    bathnum = 0
    for sample_batch in test_dataloader:
        # print bathnum
        bathnum += 1
        img1 = Variable(sample_batch[0], requires_grad=False, volatile=True).type(torch.FloatTensor)
        img2 = Variable(sample_batch[1], requires_grad=False, volatile=True).type(torch.FloatTensor)

        out = net(img1.cuda(), img2.cuda())
        labels = torch.from_numpy(np.array([float(i) for i in sample_batch[2]])).view(-1, 1)
        labels = labels.type(torch.FloatTensor)
        target = Variable(labels).cuda()

        # loss = criterion(out, target)
        print torch.stack([out, target], dim=1)
        num_images += target.size()[0]
        for i in range(target.size()[0]):
            if((target.data[i][0] == 1 and out.data[i][0] >= 0.5) or (target.data[i][0] == 0 and out.data[i][0] < 0.5)):
                num_correctly_matched += 1
    print num_images
    print num_correctly_matched
    print 'final average training accuracy = ', float(num_correctly_matched) / num_images

    # num_correctly_matched = 0
    # num_images = 0
    # bathnum = 0
    # for sample_batch in test_dataloader:
    #     print bathnum
    #     bathnum += 1
    #     img1 = Variable(sample_batch[0], requires_grad=False, volatile=True).type(torch.FloatTensor)
    #     img2 = Variable(sample_batch[1], requires_grad=False, volatile=True).type(torch.FloatTensor)
    #
    #     out = net(img1.cuda(), img2.cuda())
    #     labels = torch.from_numpy(np.array([float(i) for i in sample_batch[2]])).view(-1, 1)
    #     labels = labels.type(torch.FloatTensor)
    #     target = Variable(labels).cuda()
    #
    #     loss = criterion(out, target)
    #     num_images += target.size()[0]
    #     for i in range(target.size()[0]):
    #         if((target.data[i][0] == 1 and out.data[i][0] >= 0.5) or (target.data[i][0] == 0 and out.data[i][0] < 0.5)):
    #             num_correctly_matched += 1
    # print num_images
    # print num_correctly_matched
    # print 'final average testing accuracy = ', float(num_correctly_matched) / num_images
# read_inputs()
# create_transform_list()
# num_correctly_matched = 0
# num_correctly_matched +=1 if (3 == 1 and 4 >= 0.5) or (3== 0 and 4 < 0.5) else += 0
# print np.linspace(0, 3, 5)
# print sys.argv
#
# if ('--augment' in sys.argv):
#     print 'lksdf'
# run_test()

print_graphs()


x = Variable(torch.randn(5, 1))
print x
print torch.round(x)
# print x**2
